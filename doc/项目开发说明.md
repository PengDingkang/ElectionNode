# 项目开发说明

项目地址：[GitHub](https://github.com/PengDingkang/ElectionNode)

参考文献：赵致琢,黄小炜,吴文鑫.一种分布式计算中的容错选举算法[J].计算机研究与发展,2008(S1):93-98.



## 算法描述

>对每个进程*p*:  
> 
>初始化阶段:  
> *trust*p∶=1; *leader*p∶=⊥;*voter*p∶=∅;  
>每隔Δ*trust*p时间向*trust*p发送〈vote, *p*〉消息;
> 
>收到〈vote, *q*〉消息, 则:
> 
>1. 将*q*加入*voter*p中;
> 2. 向*q*发送〈ack, *q*〉消息;
>3. 如果|*voter*p|>-*n* 2-, 则设*leader*p∶=*p*, 并向所有进程发送〈leader, *p*〉消息, 算法终止.
> 
>收到〈leader, *q*〉消息, 则:  
> 设*leader*p∶=*q*, *trust*p∶=*q*;
>
> 若Δ*trust*p时间未收到〈ack, *trust*p〉消息, 则:  
>*trust*p∶=*trust*p+1;
> 
>若*q*∈*voter*p, 且Δq时间未收到〈vote, *q*〉消息, 则:  
> 将*q*从*voter*p表中删除.



## 算法实现

### 节点

对于该系统中的每个节点，它们会分别维护五个全局变量：

```C#
// 该节点目前标记的系统中的 Leader 节点
private static int leader = 0;

// 该节点目前的 trust 节点，节点会向自己的 trust 节点发送 vote 消息
// 由于这是一个周期性的过程，我们也将其称为心跳 heartbeat
private static int trust = 0; 

// 向该节点发送 vote 消息的节点
// 当有效的 voter 数量过半时，节点会选举自己为新的 leader
// Node 类自己维护了一个 Expired() 方法，用于检查 voter 是否有效
private static List<Node> voter = new List<Node>();

// 进程开始运作的标志
// start 请求和 leader 的广播请求会将其设置为 true
private static bool startFlag = false; 
// 标志当前节点是否为 leader。如果是，那么它将不会发送心跳
private static bool leaderFlag = false; 
```

### 初始化阶段

#### 启动监听

节点开始运行后，会在后台启动一个监听线程 `Task Run()`。  
该线程会每十秒检测一次 `startFlag`，如果为真则发送一次心跳。

#### 系统启动与持续运行

在所有节点开始运行后，向其中一个节点的 `api/start` 发送一个 `POST` 请求即可使系统开始运作。  
收到开始请求的节点会向其他所有节点广播一个开始请求，完成初始化并开始发送 `vote`。  
在初始设定的 `Leader` 节点收到超过一半的 `vote` 后，它会向所有节点广播一个 `SetLeader` 请求，以表示自己的 `Leader` 身份。至此初始化阶段结束。

系统在正常运行阶段，`Leader` 节点不会发送心跳，其他节点会定期向 `Leader` 发送心跳请求。在接收心跳请求后，`Leader` 会：

1. 检查发送者是否在自己的 `voter` 集合中。若在，则更新其有效时间。若不在，则新增该节点。
2. 检查自己是否还有过半的有效 `voter`，若有，则向所有 *不活跃* 的节点广播一个 `SetLeader` 请求，并在控制台打印该请求。
3. 在控制台打印该心跳请求，并向发送者返回 `200 OK` 响应。（发送者在收到响应后会在控制台打印该响应）

### 容错设计

#### 重新选举

在 `Leader` 节点掉线无响应时，其他节点能够作出反应并发起下一次选举。

在发出的心跳无应答的时候，节点会使其 `trust` 加一，并开始向其发送 `vote`，当有一个节点的 `vote` 过半的时候，它将成为新的 `Leader`，并开始广播 `SetLeader` 请求，完成重新选举。

#### 失效节点自动恢复

在上文中的算法基础上，我们还实现了一个失效节点自动恢复到系统中运行的功能。在一个节点掉线并重新启动后，当前的 `Leader` 节点会自动检测到它并将其重新纳入系统中运行。

在上文中我们提到

> 检查自己是否还有过半的有效 `voter`，若有，则向所有 *不活跃* 的节点广播一个 `SetLeader` 请求，并在控制台打印该请求。

`Leader` 会在收到 `vote` 时自己维护一个 `activeNodes` 列表，发送未失效的 `vote` 的所有节点都会被纳入该列表。如果它检查到自己仍然是 `Leader`，就会向所有不在此活跃列表中的节点发送一个 `SetLeader` 请求。如果一个节点刚刚重新启动，那么该请求会激活其`startFlag`，并为其设置 `truse` 和 `leader` 等当前系统状态，至此掉线的节点就能够继续正常运行了。



## 运行演示

![Example](%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91%E8%AF%B4%E6%98%8E.assets/Screenshot%202021-01-07%20214551.png)

在这里，从左到右一次是节点 0~4，由运行截图我们可以看出大致的运行过程：

* 向 `Node0` 发送开始请求后，其向另外的节点发送开始请求。其他节点开始向 `Node0` 发送 `vote`。
* 在 `Node0` 收集到来自 0，1，2 三个节点的投票后，将自己选举为 `Leader`，开始向其余两个还未向自己发送心跳的节点发送 `SetLeader` 请求。
* `Node0` 被停止（模拟节点掉线）。
* 其他节点发现 `Node0` 无响应，开始向下一个节点发送 `vote`。
* `Node1` 获得来自 1，2，3 的三票，选举自己为新的 `Leader`，开始向 0，4 发送 `SetLeader` 请求。
* 每当 `Node1` 接收心跳时，都会向不活跃节点，即 `Node0` 发送 `SetLeader` 请求。
* `Node0` 上线，接收到来自 `Node1` 的 `SetLeader` 请求，恢复运行环境，完成重新上线，系统继续正常运行。



## 总结

该容错选举算法实现了在进程及时情况下的软件容错，能在部分节点不可用时对整体系统进行调整，并维护一致性。当节点重新上线时，也能重新调整恢复其运行状态。

### 优点

在实际应用中，使用者只需要考虑硬件资源上的冗余，即增加可用的节点数，就能提高整体系统的容灾和可用性。由于硬件的发展，性能提高成本降低，软件容错方案的虽然相对调整速度较慢，但可移植性高，更加灵活，成本也更低。在此基础上，还能开发出更多功能，如节点状态波动时的均衡负载等。

### 缺点

该代码依赖于进程及时的苛刻假设，而在链路不一定及时的情况下，则需要进一步改进。
